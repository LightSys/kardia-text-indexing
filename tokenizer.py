# File description:
#
# 1.  Get long string from importer
# 2.  Split long string into multiple strings based on
#     the newline character
# 3. Tokenize the words from the array of strings

import nltk

def tokenizer(imported_string):
    string_array = imported_string.split("\n")
    
    return words;
